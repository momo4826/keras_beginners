{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "IMDB_in_keras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d1MY9L5SH4c"
      },
      "source": [
        "# Building a neural-network with Keras\n",
        "**Citation: https://github.com/slundberg/shap**\n",
        "\n",
        "(Colab is recommended)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7ZsLb8MSMZ9"
      },
      "source": [
        "First, import prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAV2JvfFR8Rv"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.datasets import imdb\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzBDb8na4CkP"
      },
      "source": [
        "Words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R177XJtc3OjU"
      },
      "source": [
        "max_features = 20000"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_2B2rg5SloT",
        "outputId": "62b2ac6e-6eab-4fdd-cadd-68eec2745011"
      },
      "source": [
        "(x_train_original, y_train_original), (x_test_original, y_test_original) = imdb.load_data(num_words=max_features)\n",
        "print('the original shape of x_train: ' + str(x_train_original.shape))\n",
        "print('the original shape of x_test: ' + str(x_test_original.shape))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the original shape of x_train: (25000,)\n",
            "the original shape of x_test: (25000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxNHM6SJ5Tw_"
      },
      "source": [
        "## Prepare the input sentences\n",
        "\n",
        "Zero-pad all these lists so that their length is the length of the longest sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zGbNPRw4Qcg"
      },
      "source": [
        "Padding handles sequences of varying length\n",
        "* The common solution to handling sequences of **different length** is to use padding.  Specifically:\n",
        "    * Set a maximum sequence length\n",
        "    * Pad all sequences to have the same length.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33Zl4NDCW1hE"
      },
      "source": [
        "maxLen = 100"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo1WqhQq0Ooo",
        "outputId": "8715d260-edba-46f4-c685-d4f59f59c1ec"
      },
      "source": [
        "x_train = sequence.pad_sequences(x_train_original, maxlen=maxLen)\n",
        "x_test = sequence.pad_sequences(x_test_original, maxlen=maxLen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (25000, 100)\n",
            "x_test shape: (25000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23-PfFDXHohX"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D39UlqN30zVb",
        "outputId": "a74c0434-b376-4846-f24a-b19506173537"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZL-wA2FP5df"
      },
      "source": [
        "After creating your model in Keras, you need to compile it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2HT1RoJ1vGs"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvC-Q_D5QGzo"
      },
      "source": [
        "## train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIdFSd86OLiJ",
        "outputId": "76ff15bb-9d4f-4eed-c332-8d273cfe38e4"
      },
      "source": [
        "model.fit(x_train, y_train_original,\n",
        "          batch_size=32,\n",
        "          epochs=15,\n",
        "          validation_data=(x_test, y_test_original))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "782/782 [==============================] - 280s 356ms/step - loss: 0.5067 - accuracy: 0.7320 - val_loss: 0.3369 - val_accuracy: 0.8542\n",
            "Epoch 2/15\n",
            "782/782 [==============================] - 277s 354ms/step - loss: 0.2403 - accuracy: 0.9073 - val_loss: 0.3582 - val_accuracy: 0.8467\n",
            "Epoch 3/15\n",
            "782/782 [==============================] - 277s 354ms/step - loss: 0.1426 - accuracy: 0.9488 - val_loss: 0.5513 - val_accuracy: 0.8353\n",
            "Epoch 4/15\n",
            "782/782 [==============================] - 278s 356ms/step - loss: 0.0833 - accuracy: 0.9717 - val_loss: 0.4868 - val_accuracy: 0.8208\n",
            "Epoch 5/15\n",
            "782/782 [==============================] - 276s 353ms/step - loss: 0.0691 - accuracy: 0.9769 - val_loss: 0.5513 - val_accuracy: 0.8110\n",
            "Epoch 6/15\n",
            "782/782 [==============================] - 277s 354ms/step - loss: 0.0507 - accuracy: 0.9829 - val_loss: 0.5659 - val_accuracy: 0.8322\n",
            "Epoch 7/15\n",
            "782/782 [==============================] - 277s 354ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.7683 - val_accuracy: 0.8332\n",
            "Epoch 8/15\n",
            "782/782 [==============================] - 278s 356ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.8373 - val_accuracy: 0.8323\n",
            "Epoch 9/15\n",
            "782/782 [==============================] - 277s 354ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.8842 - val_accuracy: 0.8325\n",
            "Epoch 10/15\n",
            "782/782 [==============================] - 278s 355ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.9674 - val_accuracy: 0.8325\n",
            "Epoch 11/15\n",
            "782/782 [==============================] - 278s 355ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.8252 - val_accuracy: 0.8240\n",
            "Epoch 12/15\n",
            "782/782 [==============================] - 277s 354ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.9000 - val_accuracy: 0.8294\n",
            "Epoch 13/15\n",
            "782/782 [==============================] - 278s 355ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.9622 - val_accuracy: 0.8286\n",
            "Epoch 14/15\n",
            "782/782 [==============================] - 277s 354ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.8348 - val_accuracy: 0.8264\n",
            "Epoch 15/15\n",
            "782/782 [==============================] - 276s 353ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.9738 - val_accuracy: 0.8250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5be59c3358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eMjGJyt2WrZ",
        "outputId": "efd7e9c8-42d6-4ca8-962f-ea3b49348acd"
      },
      "source": [
        "score, acc = model.evaluate(x_test, y_test_original,\n",
        "                            batch_size=32)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 17s 22ms/step - loss: 0.9738 - accuracy: 0.8250\n",
            "Test score: 0.9738485217094421\n",
            "Test accuracy: 0.8250399827957153\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}